{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7441039,"sourceType":"datasetVersion","datasetId":4330935},{"sourceId":7474955,"sourceType":"datasetVersion","datasetId":4351386},{"sourceId":7475889,"sourceType":"datasetVersion","datasetId":4351757},{"sourceId":9482532,"sourceType":"datasetVersion","datasetId":5768083}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image classification","metadata":{}},{"cell_type":"markdown","source":"# Phân loại các loại hoa","metadata":{}},{"cell_type":"code","source":" # Được viết trong chương 9","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T16:03:07.409827Z","iopub.execute_input":"2024-11-26T16:03:07.410227Z","iopub.status.idle":"2024-11-26T16:03:07.437238Z","shell.execute_reply.started":"2024-11-26T16:03:07.410191Z","shell.execute_reply":"2024-11-26T16:03:07.435768Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Một vài mô hình CNN nổi tiếng","metadata":{}},{"cell_type":"markdown","source":"# VGG-16 ","metadata":{}},{"cell_type":"code","source":"from torch import nn\nimport torch\n\n# Định nghĩa lớp VGG16 với số lớp đầu ra là 10 (mặc định)\nclass VGG16(nn.Module):\n    def __init__(self, num_classes=10):\n        super(VGG16, self).__init__()\n\n        # Khối 1: Conv2d, BatchNorm2d, ReLU\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  # Lớp tích chập (3 đầu vào, 64 đầu ra)\n            nn.BatchNorm2d(64),  # Chuẩn hóa đầu ra của Conv2d\n            nn.ReLU()  # Hàm kích hoạt ReLU\n        )\n        \n        # Khối 2: Conv2d, BatchNorm2d, ReLU, MaxPool\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),  # Conv2d tiếp tục với 64 đầu vào và đầu ra\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)  # Giảm kích thước với MaxPooling\n        )\n\n        # Khối 3: Conv2d, BatchNorm2d, ReLU\n        self.layer3 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  # Tích chập từ 64 lên 128 kênh\n            nn.BatchNorm2d(128),\n            nn.ReLU()\n        )\n        \n        # Khối 4: Conv2d, BatchNorm2d, ReLU, MaxPool\n        self.layer4 = nn.Sequential(\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),  # Tích chập từ 128 lên 128 kênh\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPooling để giảm kích thước\n        )\n\n        # Khối 5: Conv2d, BatchNorm2d, ReLU\n        self.layer5 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),  # Tích chập từ 128 lên 256 kênh\n            nn.BatchNorm2d(256),\n            nn.ReLU()\n        )\n        \n        # Khối 6: Conv2d, BatchNorm2d, ReLU\n        self.layer6 = nn.Sequential(\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),  # Tích chập từ 256 lên 256 kênh\n            nn.BatchNorm2d(256),\n            nn.ReLU()\n        )\n        \n        # Khối 7: Conv2d, BatchNorm2d, ReLU, MaxPool\n        self.layer7 = nn.Sequential(\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPooling để giảm kích thước\n        )\n\n        # Khối 8: Conv2d, BatchNorm2d, ReLU\n        self.layer8 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),  # Tích chập từ 256 lên 512 kênh\n            nn.BatchNorm2d(512),\n            nn.ReLU()\n        )\n        \n        # Khối 9: Conv2d, BatchNorm2d, ReLU\n        self.layer9 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU()\n        )\n        \n        # Khối 10: Conv2d, BatchNorm2d, ReLU, MaxPool\n        self.layer10 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPooling để giảm kích thước\n        )\n\n        # Khối 11: Conv2d, BatchNorm2d, ReLU\n        self.layer11 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU()\n        )\n        \n        # Khối 12: Conv2d, BatchNorm2d, ReLU\n        self.layer12 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU()\n        )\n        \n        # Khối 13: Conv2d, BatchNorm2d, ReLU, MaxPool\n        self.layer13 = nn.Sequential(\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)  # MaxPooling để giảm kích thước\n        )\n\n        # Các lớp fully connected\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5),  # Dropout để giảm overfitting\n            nn.Linear(7*7*512, 4096),  # Tầng fully connected với 4096 đầu ra\n            nn.ReLU()\n        )\n        self.fc1 = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(4096, 4096),\n            nn.ReLU()\n        )\n        self.fc2 = nn.Sequential(\n            nn.Linear(4096, num_classes)  # Lớp cuối cùng cho phân loại, với số lớp đầu ra bằng `num_classes`\n        )\n        \n    # Định nghĩa hàm forward để truyền dữ liệu qua các lớp của mạng\n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n        out = self.layer6(out)\n        out = self.layer7(out)\n        out = self.layer8(out)\n        out = self.layer9(out)\n        out = self.layer10(out)\n        out = self.layer11(out)\n        out = self.layer12(out)\n        out = self.layer13(out)\n        out = out.reshape(out.size(0), -1)  # Làm phẳng tensor để đưa vào các lớp fully connected\n        out = self.fc(out)\n        out = self.fc1(out)\n        out = self.fc2(out)\n        return out  # Trả về kết quả dự đoán của mạng\n\n# Khởi tạo mô hình VGG16 và in cấu trúc mô hình\nmodel = VGG16()\nprint(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T16:03:07.440362Z","iopub.execute_input":"2024-11-26T16:03:07.441005Z","iopub.status.idle":"2024-11-26T16:03:12.770087Z","shell.execute_reply.started":"2024-11-26T16:03:07.440946Z","shell.execute_reply":"2024-11-26T16:03:12.768795Z"}},"outputs":[{"name":"stdout","text":"VGG16(\n  (layer1): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer2): Sequential(\n    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (layer3): Sequential(\n    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer4): Sequential(\n    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (layer5): Sequential(\n    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer6): Sequential(\n    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer7): Sequential(\n    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (layer8): Sequential(\n    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer9): Sequential(\n    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer10): Sequential(\n    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (layer11): Sequential(\n    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer12): Sequential(\n    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n  )\n  (layer13): Sequential(\n    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=25088, out_features=4096, bias=True)\n    (2): ReLU()\n  )\n  (fc1): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=4096, out_features=4096, bias=True)\n    (2): ReLU()\n  )\n  (fc2): Sequential(\n    (0): Linear(in_features=4096, out_features=10, bias=True)\n  )\n)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# VGG-19","metadata":{}},{"cell_type":"code","source":"from torch import nn\nimport torch\n\n# Định nghĩa lớp VGGNet19 với số lượng lớp đầu ra là 1000 (mặc định)\nclass VGGNet19(nn.Module):\n    def __init__(self, num_classes=1000):\n        super().__init__()\n        self.__name__ = \"VGGNet19\"  # Đặt tên cho mô hình là VGGNet19\n\n        # Cấu hình cho các khối convolution (tầng tích chập)\n        self.conv_configs = [\n            # Tầng 1 và 2: 2 lớp Conv với 3 đầu vào và 64 đầu ra\n            {\n                \"in_channels\": 3,\n                \"out_channels\": 64,\n                \"num_convs\": 2,\n            },\n            # Tầng 3 và 4: 2 lớp Conv với 64 đầu vào và 128 đầu ra\n            {\n                \"in_channels\": 64,\n                \"out_channels\": 128,\n                \"num_convs\": 2,\n            },\n            # Tầng 5, 6, 7, 8: 4 lớp Conv với 128 đầu vào và 256 đầu ra\n            {\n                \"in_channels\": 128,\n                \"out_channels\": 256,\n                \"num_convs\": 4,\n            },\n            # Tầng 9, 10, 11, 12: 4 lớp Conv với 256 đầu vào và 512 đầu ra\n            {\n                \"in_channels\": 256,\n                \"out_channels\": 512,\n                \"num_convs\": 4,\n            },\n            # Tầng 13, 14, 15, 16: 4 lớp Conv với 512 đầu vào và 512 đầu ra\n            {\n                \"in_channels\": 512,\n                \"out_channels\": 512,\n                \"num_convs\": 4,\n            },\n        ]\n\n        # Cấu hình cho các khối fully connected (tầng kết nối đầy đủ)\n        self.fc_configs = [\n            # Tầng 17: với 512*7*7 đầu vào và 4096 đầu ra\n            {\n                \"in_features\": 512 * 7 * 7,\n                \"out_features\": 4096,\n            },\n            # Tầng 18: với 4096 đầu vào và 4096 đầu ra\n            {\n                \"in_features\": 4096,\n                \"out_features\": 4096,\n            },\n            # Tầng 19: với 4096 đầu vào và số lớp đầu ra (mặc định 1000)\n            {\n                \"in_features\": 4096,\n                \"out_features\": 1000,\n            },\n        ]\n\n        # Tạo các khối convolution và fully connected\n        self.conv_blocks = self._build_conv_blocks()\n        self.fc_blocks = self._build_fc_blocks()\n\n    # Hàm xây dựng các khối convolution dựa trên cấu hình\n    def _build_conv_blocks(self):\n        blocks = []\n        for conv_config in self.conv_configs:\n            in_channels = conv_config[\"in_channels\"]\n            out_channels = conv_config[\"out_channels\"]\n            num_convs = conv_config[\"num_convs\"]\n\n            layers = []\n            # Tạo các lớp Conv2d, BatchNorm2d và ReLU theo số lần conv\n            for _ in range(num_convs):\n                layers.append(\n                    nn.Conv2d(\n                        in_channels=in_channels,\n                        out_channels=out_channels,\n                        kernel_size=(3, 3),\n                        stride=(1, 1),\n                        padding=(1, 1),\n                    )\n                )\n                layers.append(nn.BatchNorm2d(out_channels))  # Sử dụng BatchNorm để ổn định huấn luyện\n                layers.append(nn.ReLU(inplace=True))  # Sử dụng ReLU làm hàm kích hoạt\n                in_channels = out_channels  # Cập nhật số lượng kênh đầu vào cho lớp tiếp theo\n\n            # Thêm MaxPooling để giảm kích thước ảnh (pooling sau các lớp Conv)\n            layers.append(nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)))\n\n            blocks.extend(layers)  # Thêm các lớp vào danh sách các khối\n\n        return nn.Sequential(*blocks)  # Chuyển danh sách thành nn.Sequential để dễ sử dụng\n\n    # Hàm xây dựng các khối fully connected dựa trên cấu hình\n    def _build_fc_blocks(self):\n        blocks = []\n\n        for i, fc_config in enumerate(self.fc_configs):\n            in_features = fc_config[\"in_features\"]\n            out_features = fc_config[\"out_features\"]\n\n            # Nếu không phải là lớp cuối cùng, thêm ReLU và Dropout để tránh overfitting\n            if i < len(self.fc_configs) - 1:\n                layers = [\n                    nn.Linear(in_features=in_features, out_features=out_features),\n                    nn.ReLU(),\n                    nn.Dropout(p=0.5),  # Dropout với xác suất 0.5 để giảm overfitting\n                ]\n            else:\n                # Lớp cuối cùng chỉ cần lớp Linear (không cần ReLU hay Dropout)\n                layers = [nn.Linear(in_features=in_features, out_features=out_features)]\n\n            blocks.extend(layers)  # Thêm các lớp vào danh sách các khối\n\n        return nn.Sequential(*blocks)  # Chuyển danh sách thành nn.Sequential để dễ sử dụng\n\n    # Định nghĩa hàm forward (truyền dữ liệu đầu vào qua các lớp của mạng)\n    def forward(self, x):\n        x = self.conv_blocks(x)  # Truyền dữ liệu qua các khối convolution\n        x = x.flatten(start_dim=1)  # Làm phẳng đầu ra trước khi đưa vào các lớp fully connected\n\n        x = self.fc_blocks(x)  # Truyền dữ liệu qua các khối fully connected\n\n        return x  # Trả về kết quả\n\n# Khởi tạo mô hình VGGNet19 và in cấu trúc mô hình\nmodel = VGGNet19()\nprint(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T16:03:12.772242Z","iopub.execute_input":"2024-11-26T16:03:12.772779Z","iopub.status.idle":"2024-11-26T16:03:14.458493Z","shell.execute_reply.started":"2024-11-26T16:03:12.772707Z","shell.execute_reply":"2024-11-26T16:03:14.456958Z"}},"outputs":[{"name":"stdout","text":"VGGNet19(\n  (conv_blocks): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): ReLU(inplace=True)\n    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (12): ReLU(inplace=True)\n    (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (16): ReLU(inplace=True)\n    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (19): ReLU(inplace=True)\n    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (22): ReLU(inplace=True)\n    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (25): ReLU(inplace=True)\n    (26): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (29): ReLU(inplace=True)\n    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (32): ReLU(inplace=True)\n    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (35): ReLU(inplace=True)\n    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (38): ReLU(inplace=True)\n    (39): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (42): ReLU(inplace=True)\n    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (45): ReLU(inplace=True)\n    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (48): ReLU(inplace=True)\n    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (51): ReLU(inplace=True)\n    (52): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc_blocks): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# InceptionNet","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\n\n# Lớp ConvBlock: định nghĩa một khối convolution đơn giản với Batch Normalization và ReLU\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, **kwargs):\n        super().__init__()\n        # Sử dụng convolution 2D với các tham số truyền vào\n        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n        # Áp dụng Batch Normalization để ổn định việc huấn luyện\n        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # Áp dụng convolution, batch normalization và hàm kích hoạt ReLU\n        x = self.bn(self.conv(x))\n        return F.relu(x, inplace=True)\n\n# Lớp InceptionBlock: khối Inception chính với nhiều nhánh (branches)\nclass InceptionBlock(nn.Module):\n    def __init__(\n        self,\n        in_channels,             # Số lượng channels đầu vào\n        out_1x1,                 # Số lượng channels của nhánh 1x1\n        outinception_3x3_reduced, # Số lượng channels giảm trước khi áp dụng 3x3\n        outinception_3x3,        # Số lượng channels của nhánh 3x3\n        outinception_5x5_reduced, # Số lượng channels giảm trước khi áp dụng 5x5\n        outinception_5x5,        # Số lượng channels của nhánh 5x5 (thực tế là hai lớp 3x3)\n        out_pool                 # Số lượng channels của nhánh MaxPooling\n    ):\n        super().__init__()\n\n        # Nhánh 1: Convolution 1x1 đơn giản\n        self.branch1 = ConvBlock(\n            in_channels, out_1x1, kernel_size=1, stride=1\n        )\n\n        # Nhánh 2: Convolution 1x1 để giảm số channels sau đó là Convolution 3x3\n        self.branch2 = nn.Sequential(\n            ConvBlock(in_channels, outinception_3x3_reduced, kernel_size=1),\n            ConvBlock(outinception_3x3_reduced, outinception_3x3, kernel_size=3, padding=1),\n        )\n\n        # Nhánh 3: Convolution 1x1 giảm số lượng channels rồi áp dụng hai lớp Conv 3x3\n        # Điều này hiệu quả hơn so với việc sử dụng một lớp 5x5 trực tiếp.\n        self.branch3 = nn.Sequential(\n            ConvBlock(in_channels, outinception_5x5_reduced, kernel_size=1),\n            ConvBlock(outinception_5x5_reduced, outinception_5x5, kernel_size=3, padding=1),\n            ConvBlock(outinception_5x5, outinception_5x5, kernel_size=3, padding=1),\n        )\n\n        # Nhánh 4: MaxPooling để giảm kích thước không gian, sau đó là Convolution 1x1\n        self.branch4 = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            ConvBlock(in_channels, out_pool, kernel_size=1),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # Áp dụng từng nhánh và kết hợp kết quả từ các nhánh bằng hàm torch.cat\n        y1 = self.branch1(x)\n        y2 = self.branch2(x)\n        y3 = self.branch3(x)\n        y4 = self.branch4(x)\n\n        # Kết hợp đầu ra từ các nhánh bằng cách ghép lại theo chiều số lượng channels\n        return torch.cat([y1, y2, y3, y4], 1)\n\n# Lớp Inception: định nghĩa toàn bộ mô hình Inception với các khối liên tiếp\nclass Inception(nn.Module):\n    def __init__(self, img_channel):\n        super().__init__()\n\n        # Lớp convolution đầu tiên để xử lý đầu vào\n        self.first_layers = nn.Sequential(\n            ConvBlock(img_channel, 192, kernel_size=3, padding=1)\n        )\n\n        # Các khối Inception nối tiếp nhau\n        self.inception_3a = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n        self.inception_3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n\n        # Lớp MaxPooling để giảm kích thước không gian\n        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # Tiếp tục thêm các khối Inception trong tầng 4 và 5\n        self.inception_4a = InceptionBlock(480, 192, 96, 208, 16, 48, 64)\n        self.inception_4b = InceptionBlock(512, 160, 112, 224, 24, 64, 64)\n        self.inception_4c = InceptionBlock(512, 128, 128, 256, 24, 64, 64)\n        self.inception_4d = InceptionBlock(512, 112, 144, 288, 32, 64, 64)\n        self.inception_4e = InceptionBlock(528, 256, 160, 320, 32, 128, 128)\n\n        self.inception_5a = InceptionBlock(832, 256, 160, 320, 32, 128, 128)\n        self.inception_5b = InceptionBlock(832, 384, 192, 384, 48, 128, 128)\n\n        # Lớp trung bình gộp (AvgPool) để giảm kích thước không gian về 1x1\n        self.avg_pool = nn.AvgPool2d(kernel_size=8, stride=1)\n        # Lớp fully connected để đưa ra kết quả phân loại\n        self.fc = nn.Linear(1024, 10)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        out: torch.Tensor\n        # Áp dụng lớp convolution đầu tiên\n        out = self.first_layers(x)\n\n        # Áp dụng các khối Inception trong tầng 3\n        out = self.inception_3a(out)\n        out = self.inception_3b(out)\n        out = self.max_pool(out)\n\n        # Áp dụng các khối Inception trong tầng 4\n        out = self.inception_4a(out)\n        out = self.inception_4b(out)\n        out = self.inception_4c(out)\n        out = self.inception_4d(out)\n        out = self.inception_4e(out)\n        out = self.max_pool(out)\n\n        # Áp dụng các khối Inception trong tầng 5\n        out = self.inception_5a(out)\n        out = self.inception_5b(out)\n\n        # Áp dụng lớp trung bình gộp và đưa về dạng vector\n        out = self.avg_pool(out)\n        out = out.view(out.size(0), -1)\n\n        # Trả về kết quả sau khi qua lớp fully connected\n        return self.fc(out)\n\n# Hàm main: tạo mô hình và kiểm tra kích thước đầu ra với một input mẫu\ndef main() -> None:\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    net = Inception(1).to(device)  # Khởi tạo mô hình Inception với 1 channel đầu vào\n    x = torch.randn(3, 1, 32, 32, device=device)  # Tạo một input giả kích thước (3, 1, 32, 32)\n\n    y: torch.Tensor = net(x)  # Tính toán đầu ra của mô hình với input x\n    print(f'{y.size() = }')  # In kích thước của đầu ra\n\n# Tạo mô hình Inception và in cấu trúc mô hình\nmodel = Inception(1)\nprint(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T16:03:14.460152Z","iopub.execute_input":"2024-11-26T16:03:14.460636Z","iopub.status.idle":"2024-11-26T16:03:14.633087Z","shell.execute_reply.started":"2024-11-26T16:03:14.460584Z","shell.execute_reply":"2024-11-26T16:03:14.631897Z"}},"outputs":[{"name":"stdout","text":"Inception(\n  (first_layers): Sequential(\n    (0): ConvBlock(\n      (conv): Conv2d(1, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (inception_3a): InceptionBlock(\n    (branch1): ConvBlock(\n      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): ConvBlock(\n        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (1): ConvBlock(\n        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception_3b): InceptionBlock(\n    (branch1): ConvBlock(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): ConvBlock(\n        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (1): ConvBlock(\n        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (max_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (inception_4a): InceptionBlock(\n    (branch1): ConvBlock(\n      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): ConvBlock(\n        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (1): ConvBlock(\n        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception_4b): InceptionBlock(\n    (branch1): ConvBlock(\n      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): ConvBlock(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (1): ConvBlock(\n        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception_4c): InceptionBlock(\n    (branch1): ConvBlock(\n      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): ConvBlock(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (1): ConvBlock(\n        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception_4d): InceptionBlock(\n    (branch1): ConvBlock(\n      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): ConvBlock(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (1): ConvBlock(\n        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception_4e): InceptionBlock(\n    (branch1): ConvBlock(\n      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): ConvBlock(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (1): ConvBlock(\n        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception_5a): InceptionBlock(\n    (branch1): ConvBlock(\n      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): ConvBlock(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (1): ConvBlock(\n        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (inception_5b): InceptionBlock(\n    (branch1): ConvBlock(\n      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch2): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch3): Sequential(\n      (0): ConvBlock(\n        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): ConvBlock(\n        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): ConvBlock(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (branch4): Sequential(\n      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (1): ConvBlock(\n        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (avg_pool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n  (fc): Linear(in_features=1024, out_features=10, bias=True)\n)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# ResNet","metadata":{}},{"cell_type":"code","source":"from torch import nn\nimport torch\n\n# Lớp Downsample: giảm kích thước không gian (spatial dimensions) của input nếu cần\nclass Downsample(nn.Module):\n    def __init__(self, in_channels, out_channels, stride):\n        super().__init__()\n        # Sử dụng convolution 1x1 để giảm số lượng channels\n        self.conv = nn.Conv2d(\n            in_channels, out_channels, kernel_size=1, stride=stride, bias=False\n        )\n        # Áp dụng Batch Normalization để ổn định việc huấn luyện\n        self.bn = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x):\n        # Áp dụng convolution và Batch Normalization\n        x = self.conv(x)\n        x = self.bn(x)\n        return x\n\n\n# Lớp Bottleneck: khối cơ bản của ResNet-50, có cấu trúc gồm ba lớp convolution\nclass Bottleneck(nn.Module):\n    def __init__(\n        self, in_channels, hidden_channels, out_channels, stride=1, downsample=None\n    ):\n        super().__init__()\n        # Lớp conv1: convolution 1x1 để giảm số lượng channels\n        self.conv1 = nn.Conv2d(\n            in_channels, hidden_channels, kernel_size=1, stride=1, bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(hidden_channels)\n        \n        # Lớp conv2: convolution 3x3 để học đặc trưng không gian\n        self.conv2 = nn.Conv2d(\n            hidden_channels,\n            hidden_channels,\n            kernel_size=3,\n            stride=stride,\n            padding=1,\n            bias=False,\n        )\n        self.bn2 = nn.BatchNorm2d(hidden_channels)\n        \n        # Lớp conv3: convolution 1x1 để tăng số lượng channels\n        self.conv3 = nn.Conv2d(\n            hidden_channels, out_channels, kernel_size=1, stride=1, bias=False\n        )\n        self.bn3 = nn.BatchNorm2d(out_channels)\n        \n        # Downsample nếu cần để đảm bảo kích thước khớp với đầu ra\n        self.downsample = downsample\n        \n        # Hàm kích hoạt ReLU\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        identity = x  # Lưu lại giá trị input để dùng cho kết nối tắt (skip connection)\n\n        # Áp dụng conv1, bn1\n        out = self.conv1(x)\n        out = self.bn1(out)\n\n        # Áp dụng conv2, bn2\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        # Áp dụng conv3, bn3\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        # Sử dụng downsample nếu cần để khớp kích thước giữa input và output\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        # Cộng giá trị input (identity) với output từ các lớp convolution\n        out += identity\n        \n        # Áp dụng hàm kích hoạt ReLU\n        out = self.relu(out)\n\n        return out\n\n\n# Lớp ResNet50: định nghĩa kiến trúc tổng thể của mạng ResNet-50\nclass ResNet50(nn.Module):\n    def __init__(self, num_classes=1000):\n        super().__init__()\n        self.__name__ = \"ResNet50\"\n\n        # Lớp conv1: convolution 7x7 để xử lý đầu vào (input) ban đầu\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu1 = nn.ReLU(inplace=True)\n        \n        # Lớp maxpool1: giảm kích thước không gian của output\n        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        \n        # Định nghĩa layer1: gồm 3 Bottleneck, trong đó block đầu tiên có downsample\n        self.layer1 = nn.Sequential(\n            Bottleneck(\n                in_channels=64,\n                hidden_channels=64,\n                out_channels=256,\n                stride=1,\n                downsample=Downsample(in_channels=64, out_channels=256, stride=1),\n            ),\n            Bottleneck(in_channels=256, hidden_channels=64, out_channels=256, stride=1),\n            Bottleneck(in_channels=256, hidden_channels=64, out_channels=256, stride=1),\n        )\n        \n        # Định nghĩa layer2: gồm 4 Bottleneck, trong đó block đầu tiên có downsample\n        self.layer2 = nn.Sequential(\n            Bottleneck(\n                in_channels=256,\n                hidden_channels=128,\n                out_channels=512,\n                stride=2,\n                downsample=Downsample(in_channels=256, out_channels=512, stride=2),\n            ),\n            Bottleneck(\n                in_channels=512, hidden_channels=128, out_channels=512, stride=1\n            ),\n            Bottleneck(\n                in_channels=512, hidden_channels=128, out_channels=512, stride=1\n            ),\n            Bottleneck(\n                in_channels=512, hidden_channels=128, out_channels=512, stride=1\n            ),\n        )\n        \n        # Định nghĩa layer3: gồm 6 Bottleneck, trong đó block đầu tiên có downsample\n        self.layer3 = nn.Sequential(\n            Bottleneck(\n                in_channels=512,\n                hidden_channels=256,\n                out_channels=1024,\n                stride=2,\n                downsample=Downsample(in_channels=512, out_channels=1024, stride=2),\n            ),\n            Bottleneck(\n                in_channels=1024, hidden_channels=256, out_channels=1024, stride=1\n            ),\n            Bottleneck(\n                in_channels=1024, hidden_channels=256, out_channels=1024, stride=1\n            ),\n            Bottleneck(\n                in_channels=1024, hidden_channels=256, out_channels=1024, stride=1\n            ),\n            Bottleneck(\n                in_channels=1024, hidden_channels=256, out_channels=1024, stride=1\n            ),\n            Bottleneck(\n                in_channels=1024, hidden_channels=256, out_channels=1024, stride=1\n            ),\n        )\n        \n        # Định nghĩa layer4: gồm 3 Bottleneck, trong đó block đầu tiên có downsample\n        self.layer4 = nn.Sequential(\n            Bottleneck(\n                in_channels=1024,\n                hidden_channels=512,\n                out_channels=2048,\n                stride=2,\n                downsample=Downsample(in_channels=1024, out_channels=2048, stride=2),\n            ),\n            Bottleneck(\n                in_channels=2048, hidden_channels=512, out_channels=2048, stride=1\n            ),\n            Bottleneck(\n                in_channels=2048, hidden_channels=512, out_channels=2048, stride=1\n            ),\n        )\n        \n        # Lớp avgpool: adaptive pooling để giảm kích thước xuống 1x1\n        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n        \n        # Lớp fully connected (fc) để phân loại đầu ra\n        self.fc = nn.Linear(2048, num_classes)\n\n    # Định nghĩa hàm forward: xử lý các bước tính toán trên input x\n    def forward(self, x):\n        # Xử lý đầu vào qua conv1, bn1, ReLU, maxpool1\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu1(x)\n        x = self.maxpool1(x)\n\n        # Xử lý qua các layer\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        # Sử dụng adaptive average pooling và flatten để chuyển về vector\n        x = self.avgpool(x)\n        x = x.flatten(start_dim=1)\n        \n        # Dùng fully connected layer để đưa ra kết quả cuối cùng\n        x = self.fc(x)\n\n        return x\n\n# Tạo mô hình ResNet-50 và in ra cấu trúc của nó\nmodel = ResNet50()\nprint(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T16:03:14.636136Z","iopub.execute_input":"2024-11-26T16:03:14.636655Z","iopub.status.idle":"2024-11-26T16:03:14.944041Z","shell.execute_reply.started":"2024-11-26T16:03:14.636599Z","shell.execute_reply":"2024-11-26T16:03:14.942691Z"}},"outputs":[{"name":"stdout","text":"ResNet50(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu1): ReLU(inplace=True)\n  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Downsample(\n        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (relu): ReLU(inplace=True)\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Downsample(\n        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (relu): ReLU(inplace=True)\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Downsample(\n        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (relu): ReLU(inplace=True)\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Downsample(\n        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (relu): ReLU(inplace=True)\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n)\n","output_type":"stream"}],"execution_count":5}]}